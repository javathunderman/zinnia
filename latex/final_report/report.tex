\documentclass[12pt]{article}
\usepackage[backend=biber]{biblatex}
\addbibresource{report.bib}
\usepackage[T1]{fontenc}
\usepackage{graphicx} % Required for inserting images
\usepackage[margin=1in]{geometry}
\usepackage{xcolor}
\usepackage{listings}
\usepackage{mathpartir}
\usepackage{minted}
\usepackage{xparse}
\usepackage{graphicx}
\usepackage[normalem]{ulem}
\usepackage{soul}
\usepackage{float}
\usepackage{hyperref}
\usepackage{amsmath}
\usepackage{xspace}
\usepackage{euler}
\usepackage{amsfonts}
\usepackage{mathtools}
\usepackage{subcaption}
\usepackage[nounderscore]{syntax}
\usepackage{circuitikz}

\NewDocumentCommand{\codeword}{v}{%
\texttt{\textcolor{blue}{#1}}%
}
\usepackage{hyperref}

\input type_macros

\title{CMSC838L - Final report}
\author{Arjun Vedantham \\ Yusuf Bham}
\date{May 2024}

\begin{document}

\maketitle

\section{Introduction and Motivation}
Digital signal processing techniques are extremely important in telecommunications, computer vision, and a number of other related fields.
In particular, digital signal processing techniques form a key component behind the idea of software defined radio (SDR),
which refers to analyzing digital samples that represent radio signals with software, instead of discrete hardware components that operate
over signals in analog formats. Software defined radio presents a notable improvement in flexibility for radio engineers, and removes the
need for specialized hardware components - instead, new signal demodulation techniques or formats can be deployed just through a simple software
update.

SDR users typically define signal processing pipelines using platforms like GNURadio. GNURadio presents a graphical format for creating these
pipelines, with discrete blocks representing a signal source, signal sink, or an intermediate step in the processing pipeline. As an example,
see the "flowgraph" (as called in GNURadio's documentation) below. This starts by instantiating a signal source from an RTL-SDR (a type of hobbyist SDR that can be used
over USB with consumer PCs), and sets both a sampling rate (32000 Hz) and a listening frequency (signals at 433 MHz). From here, these samples
are fed into a low pass filter block (which smooths out high frequency noise in the signal), and the resulting signal is transformed into
a stream that is passed to a GUI block that graphs the signal, using a Fast Fourier Transform (FFT) to move the signal into the frequency domain.

This simple flowgraph is stored in an XML format, and is used by GNURadio's backend to generate a Python script that actually runs the defined
processing pipeline. In addition, there are also C/C++ modules loaded into the runtime system for low level tasks - for instance, a USB driver for the SDR.

\includegraphics[width=\linewidth]{images/gnuradio.png}

\subsection{Problems Identified with State of the Art}
There are number of problems with this current approach. First, GNURadio's practice of emitting Python scripts means that parallelism is
limited on two fronts - first, because of language design choices (Python's infamous "global interpreter lock", which essentially forbids
runtime concurrency), and also because we are ultimately running this script on standard PC hardware, which uses an inherently sequential
von Neumann architecture. Additionally, as previously mentioned, there is also an extensive library of C/C++ modules, and the implementation
of these modules are opaque to the Python-level code generated by GNURadio's flowgraph compiler.

As such, we identified two research questions that we aimed to answer in this project:

\begin{itemize}
    \item Could we use hardware acceleration to get better performance and greater parallelism for DSP applications?
    \item Could we design a language that is more conducive to defining correct DSP pipelines?
\end{itemize}

\section{Literature Review}
We started by conducting a literature review of existing languages designed for DSP problems.
\subsection{Ziria}
One of the first papers we considered as Ziria \cite{stewart_ziria_2015}, a domain specific language that was
designed to aid development in implementations of the physical layer of wireless protocols.
Ziria presented a functional language design syntax, and was specifically intended for wireless protocol
implementations on IOT hardware. As such, it contained many primitives that we thought would
be important to add to our language - for instance, an "FFT" primitive function. However Ziria had a key limitation -
it was designed for standard CPUs, which meant that there were still parallelism limitations.

\subsection{Calyx}
One technique generally used for hardware acceleration for specialized applications like this
is to deploy them to FPGAs. One example of this was the Catapult paper that we read in class,
where Microsoft deployed FPGAs to accelerate running PageRank as part of their Bing server infrastructure.
However, FPGAs are notoriously difficult to program, and generally require extremely fine-grained circuit
configurations written in a hardware description language like Verilog.

Calyx \cite{nigam_compiler_2021} is an intermediate representation for compilers developed by the CAPRA research group at Cornell.
It defines circuits in three distinct parts - a collection of memories (consisting of combinational memories/
flip-flops and registers), wire groups (which denote assignments between different memory components
in the circuit), and a statically defined control schedule that orders wire assignments.
Calyx has already been used in the Filament HDL, another domain specific language project from the CAPRA
group that incorporated signal timing into the language's type system.

\section{Technical Contribution}
We decided to use the Calyx IR and design a more general, hardware acceleratable language for DSP tasks, called Zinnia.
\footnote{Named "Zinnia" because "calyx" refers to the petals of a flower and zinnias are a type of flower. Plus it sounds like Ziria.}
We also considered emitting circuits using CIRCT, the LLVM framework that allows compilers to generate
MLIR that is subsequently lowered to a Verilog hardware description, however we quickly found that
CIRCT lacked the project maturity needed to develop even a basic language around it. This included
no binaries to link against, thus requiring us to compile a large subset of the LLVM project, which was not practical.
Calyx also had better documentation for its IR, and a small standard library of memory cells that could be easily integrated
into circuits synthesized when the compiler lowers from the IR to a Verilog hardware description.

\subsection{Parsing and Typing}
Zinnia is backed by a bidirectional type system, heavily inspired by Complete and Easy Bidirectional Typing for Higher-Rank Polymorphism and Purescript \cite{dunfield_complete_2013}. Also similarly to Purescript, while the system is based on CAEBDT, our system doesn't use the ``main'' takeaway of the paper -- an ordered context, and stays with a more simple one. This was largely due to familiarity, and in the future we would like to rewrite it to use ordered contexts. The choice of a bidirectional type system stems from its ease of extensibility compared to HM, which is the more common choice for a language like this. This extensibility allows us to more easily add features like linear typing in the future, which is important in this space as it means we can keep the \textit{pure} and \textit{functional} aspect, while still preserving performance and memory constraints. Currently types are restricted to functions and primitives, just due to time constraints. General universal quantification is supported, but access to it is currently limited to the \texttt{scan} primitive. While generics over types are generally supported, being generic over a \textit{value} is currently restricted to the vector primitive.

Full semantics and syntax for our language can be found at the end of our report.

\subsection{Code Generation}
The compiler that we wrote for Zinnia traverses the AST recursively. Since there is no concept of dynamic
memory allocation for circuits, we focused on generating the required memories for the circuit first.

At the top level, "let" bindings are used to generate register memories (for integers) and combinational memories
(for vectors). For constant values, we use Calyx's "structure" macro to instantiate a "constant" register with the
requried value at compile time, which is subsequently removed in the process of optimization and lowering to Verilog.
Variable bindings are stored in a hashmap and are accessed using either the component name (which is guaranteed
to be unique through the Calyx frontend API) or the user-defined variable name.

For binary operations or if expressions, we need to use comparator primitives and wire them correctly - to do this,
we call the memory generation function on each of the parameters of the operation, and then use a "wire"
generation function which generates assignments between the inputs and outputs of the memories and logical primitives.
After this is complete, we generate a small schedule of operations depending on the subexpression that we are compiling, using
the Calyx "seq" block to sequentially order operations (e.g. ensuring that a register memory gets its constant value
before the addition actually takes place). Finally, the top most register memory's value is copied into a specially
instantiated combinational memory. This is because register memories in Calyx do not have latching/persistence guarantees,
however, values in combinational/vector memories can be examined as part of the circuit simulation.

\begin{figure}[!ht]
    \centering
    \resizebox{1\textwidth}{!}{%
    \begin{circuitikz}
    \tikzstyle{every node}=[font=\LARGE]
    \node [font=\LARGE] at (5,16.75) {(let ((x, 10), (y, 8)) (+ x y))};
    \draw  (0.5,17.5) rectangle (9.5,16);
    \draw  (2.25,17.25) rectangle (4.5,16.25);
    \draw  (4.5,17.25) rectangle (6.75,16.25);
    \draw  (7,17.25) rectangle (9.25,16.25);
    \draw [](1.25,16) to[short] (1.25,13.5);
    \draw [](3.5,16.25) to[short] (3.5,14.5);
    \draw [](5.75,16.25) to[short] (5.75,14.5);
    \draw [](8.75,16.25) to[short] (8.75,14.5);
    \node [font=\LARGE] at (1,12.75) {Let};
    \node [font=\LARGE] at (5,14) {Binding (Id, Value)};
    \node [font=\LARGE] at (13.75,13.25) {Binop(Id, Id)};
    \draw [](8.75,14.5) to[short] (12,14.5);
    \draw [](12,14.5) to[short] (12,13.75);
    \draw  (8.5,10.5) rectangle (15,9);
    \draw  (8.5,7.5) rectangle (15,6);
    \node [font=\LARGE] at (11.5,9.75) {x: reg0: 10};
    \node [font=\LARGE] at (11.5,6.75) {y: reg1: 8};
    \draw[] (8.5,9.75) to[short] (5.5,9.75);
    \draw[] (8.5,6.5) to[short] (5.5,6.5);
    \draw  (-0.25,9.5) rectangle (4.75,8);
    \draw  (-0.25,8) rectangle (4.75,6.75);
    \node [font=\LARGE] at (1.75,8.75) {adder};
    \node [font=\LARGE] at (2,7.5) {adder\_res};
    \draw [](5.5,9.75) to[short] (5.5,9);
    \draw[] (5.5,9) to[short] (4.75,9);
    \draw [](5.5,6.5) to[short] (5.5,7.25);
    \draw[] (5.5,7.25) to[short] (4.75,7.25);
    \draw [](2.25,6.75) to[short] (2.25,4.25);
    \draw  (-0.25,4.25) rectangle (5,2.75);
    \node [font=\LARGE] at (2.25,3.5) {res\_mem};
    \end{circuitikz}
    }%
    \caption{Simplified compilation/memory instantiation flow for a Zinnia program.}
    \end{figure}

\subsection{Supporting Parallelization in Compilation}
One of the main goals of our DSL was to improve parallelism. While Calyx has a "par" primitive for parallelizing parts of the circuit,
Zinnia currently only generates circuits using the "seq" ("sequential") control flow keyword for easier debugging and testing. Even though parallelism
at the user level is limited, we still hoped to expose some of the potential parallel speedups through the use
of a function primitive that could be used to get implicit parallelism.

\subsubsection{Prefix Sums Scan}
To expose some parallelism without explicitly supporting compiling using the "par" control flow block,
we implemented a version of parallel scan using the prefix sums algorithm \cite{blelloch_prefix_1990}. This primitive takes
a reference to a vector with 8 integers and performs the addition operation, returning a modified
array where the latter half of the array contains the scan result.

This function was supposed to be invoked as a primitive within the language, with the compiler inlining
a separate Calyx component whose input memories would be populated with a reference to the vector supplied
by the caller. However, while we were able to test the scan component as a separate circuit generated from our
hand-written IR code, we were not able to fully resolve linking issues that would allow us to pass memories by
reference into subcomponents.

\begin{figure}[H]
    \centering
    \includegraphics[height=20em]{images/prefix\_sums.png}
    \caption{Screenshot of the final state of the prefix sums array - a separate vector memory
    is instantiated in the IR implementation to track the intermediate values as they flow
    up and down the prefix-sums tree.}
\end{figure}

\section{Evaluation}
We decided to evaluate our language in three different ways: correctness testing, scalability testing, and hardware testing.
\subsection{Correctness Testing}
To verify the correctness of the language, we attmepted to use the Cocotb RTL testing framework and the Icarus Verilog simulator. This allows
us to run a simulated version of the circuit's clock and write unit tests around elements of the circuits
that we generate. Although we did not have time to implement extensive tests, we were able to informally verify
correct execution using unit tests for the binary operations supported by the language,
as well as correct outputs values for the scan primitive (which was tested separately since we could not link
this into the language easily) through Icarus Verilog. We were also able to generate timing diagrams that we
could view with GTKWave, and this showed that values used during the circuit's evaluation were being loaded into registers correctly.
However, we would have wanted to use randomized testing with cocotb to be more confident in our compiler's correctness.

\begin{figure}
    \includegraphics[width=\linewidth]{images/timing_sim.png}
    \caption{Example timing diagram for the program shown in Figure 1. The operands (represented in hex form here) are loaded into reg0 and reg1, before being loaded into the "left" and "right" inputs of the combinational adder. The adder register's result (5th line down) is then moved into the "output" combinational memory using its "write\_data" line. Finally, the last line displays the clock signal for the whole circuit. }
\end{figure}
\subsection{Scalability Testing}
Second, we wanted to test the scalability of our language. For this, we focused on evaluating the "scan" primitive, since
it is the main way end-users would be able to obtain parallelism through the language (at least, as it is currently implemented).
We found that in simulation, our parallel scan implementation always took 71 cycles to generate outputs, given a set of 8 integers
to iterate over. While parallel scan theoretically provides work bounds of $O(n)$ and span bounds of $O(lg(n))$, in practice the
work and span bounds of our implementation are worse. This is because we were not sure if it was possible to instantiate
an arbitrarily high number of registers, so we focused on using the combinational memory primitives to hold intermediate values
(particularly between the "sweep-up" and "sweep-down" phases of parallel scan). Combinational memory primitives in the Calyx IR
are exclusive read/write memory cells, and take at least one cycle to set the data address and read the stored value out of the memory
into a register. This restriction essentially limited the parallelism that we could achieve to only a few steps of the algorithm - specifically,
summing values between nodes at each level of the prefix sums tree, since the additions were purely combinational and depended only
on values in registers that were ready to go at the last cycle.
\subsection{Physical Testing}
We hoped to eventually deploy circuits that were synthesized using Zinnia to a Lattice Icestick FPGA.
This FPGA can be used with consumer devices over a USB connection, and has a large library of open source tooling.
This includes the Yosys synthesis toolkit (which handles transforming high level Verilog hardware descriptions into
lower level RTL circuits), the nextpnr place and route tool (which handles connections between logic units
on the FPGA), and iceprog, an open source programming tool that could deploy circuits with complete routing
to the flash memory on-board the Icestick.

Circuits synthesized by Calyx include three signals by default - a "go" line, which when activated,
activates the circuit, a "clk" (clock) line, which handles cycle-level signalling for the sequential logic
elements of the circuit, and a "reset" line, which can be used to reset the circuit while active.

In order to actually use the synthesized circuits, the "go" line must be pulled to logical high, and
while the reset lines needed to be set to logical low, and the clock line must be tied to the 12 MHz
oscillator built into the Icestick. Values for the "scan" primitive could then be loaded in from the Icestick's
block RAM module.

To support dynamically loading values into block RAM, we wrote a small serial communication driver for the Icestick.
Specifically, this was a form of one way (half-duplex) SPI, with an Arduino serving as the primary device on the SPI
bus, and the Icestick serving as the secondary device. We chose SPI because it is relatively easy to implement
on the receiving side (in fact, a shift register is enough to receive data transmitted over the data line).
While testing the SPI driver, we wanted to use an external clock source to control the speed of data transmission,
and ensure that the Icestick was sampling the data line in phase with the transmitting device's clock (in this case
an Arduino). Unfortunately, setting the clock line for the circuit loaded onto the FPGA also sets the clock line
for the USB programmer chip, which requires a 12MHz signal in order to function correctly. This misconfiguration
prevented us from loading new circuits onto the FPGA, and required us to use simulation as our primary evaluation
method instead.
\begin{figure}[H]
\includegraphics{images/spi.png}
\caption{Half duplex SPI waveform, where an Arduino would have controlled the SCK and SDO lines and the FPGA would bit shift
the received values in block RAM.}
\cite{mathworks_support_nodate}
\end{figure}
\section{Conclusion}
In the end, we were able to implement a version of the scan primitive in the Calyx IR, implement a bidirectional
typing system, add some basic language features into our language, and use external circuit verification and simulation
tools to show that our circuits performed as the high level program specified.

However, there is still room for improvement, both in terms of feature support and performance - we do not have support for looping structures,
even though the Calyx IR supports it. Additionally, our parallelism benefits are limited by the fact that we can only really exploit
the parallelism present in the hardware through the scan primitive, even though Calyx supports parallelized control schedules. While part of this
is due to limitations in the Calyx standard library, future libraries could be used to enable concurrent read/exclusive write
accesses to these memories instead of the current exclusive read/write access pattern.

We were also not able to show our circuits running on real hardware, which was the ultimate goal of the project.

One obstacle that we did not foresee was the difficulty of working with the Calyx IR from Rust. While LLVM's CIRCT project
has a robust Rust API, it seems that the authors of the Calyx IR primarily want language authors to use their IR from
a Python builder module or the CIRCT toolchain, even though the Filament HDL (which was authored by the same research
group and uses Calyx as its IR) is also written in Rust. For some issues, like linking against the combinational memory
primitives or inlining other components, the Rust library documentation was so poor that we ended up looking through
Filament's implementation and using that as a guide for building our compiler.

Altogether, this was a very interesting exploration into building a domain specific language that interacted so closely
with hardware, and was a great way to get experience with compilers, parallel algorithms, type systems, and using FPGAs.
We hope to continue working on Zinnia as a hobby research project over the summer.

The codebase for Zinnia is available on GitHub: \url{https://github.com/javathunderman/zinnia}

\section{Syntax}
\setlength{\grammarparsep}{20pt plus 1pt minus 1pt}
\setlength{\grammarindent}{12em}

\begin{grammar}

<decl> ::= "let" <ident>":" <ty> "=" <expr>";"

<ident> ::= (<letter> | \_) \{<letter> | 0..9 | \_\}

<ty> ::= "()"
    \alt "bool"
    \alt <num-ty>
    \alt "Vec<"<num-ty>"," \{0..9\}$^+$">"

<num-ty> ::= ("u" | "i") \{0..9\}$^+$

<expr> ::= "()"
    \alt <bool-lit>
    \alt <int-lit>
    \alt <vec-lit>
    \alt "("\{<expr>\}$^+$")"
    \alt "("<expr> <bop> <expr>")"
    \alt "(let ("<binders>")" <expr>")"
    \alt "(if" <expr> <expr> <expr>")"

<binders> ::= <binder> \alt <binder>"," <binders>

<binder> ::= "("<ident>"," <expr>")"
\alt "("<ident>": " <ty>"," <expr>")"

<num-cmp-op> ::= ">" \alt ">=" \alt "<" \alt "<="

<num-op> ::= "+" \alt "-" \alt "*" \alt "/"

<cmp-op> ::= "==" \alt "!="

<bop> ::= <num-op>
\alt <num-cmp-op>
\alt <cmp-op>

<int-lit> ::= [-]\{0..9\}$^+$
    \alt [-]\{0..9\}$^+$ ("u" | "i") \{0..9\}$^+$

<bool-lit> ::= "true" \alt "false"

<vec-lit> ::= "["<vec-elems>"]"

<vec-elems> ::= <int-lit> \alt <int-lit>"," <vec-elems>
\end{grammar}

\section{Typing}
\begin{figure*}[htbp]
    \[
        \begin{array}{llcll}
            \text{Types} & A, B, C & \bnfas &
            \unitty &\bnfalt \alpha \bnfalt \exvar{\alpha} \\ & & & &\bnfalt \faty{\alpha}{A} \\ & & & &\bnfalt A_1, \dots, A_n \to B
            \\[8pt]
            \text{Monotypes} & \tau,\sigma,\pi & \bnfas &
            \unitty &\bnfalt \alpha \bnfalt \exvar{\alpha} \\
                    & & & &\bnfalt \tau_1, \dots, \tau_n \to \sigma \\
                    & & & &\bnfalt \vartheta \bnfalt \vartheta_{i, s} \bnfalt \exvar{\vartheta} \bnfalt \exvar{\vartheta}_{i, s} \\
                    & & & &\bnfalt \vecty{\tau}{c} \bnfalt \exvar{\evecty} \\
                    & & & &\bnfalt \boolty
            \\[8pt]
            \text{Contexts} & \Gamma, \Delta, \Theta & \bnfas &
            \cdot
                            &\bnfalt \Gamma, \alpha
            \bnfalt \Gamma, (x:A)
        \end{array}
    \]
    \caption{Syntax of types, monotypes, and contexts.}
\end{figure*}

\begin{figure*}[htbp]
    \judgbox{\judgetp{\Gamma}{A}}%
    {Under context $\Gamma$, type $A$ is well-formed.}\\
    \judgbox{\judgetps{\Gamma}{n}{A}}%
    {Under context $\Gamma$, types $\family{A}{n}$ are well-formed.}

    \begin{mathpar}
        \Infer{\rulename{UnitWF}}
        { }
        {\judgetp{\Gamma}{\unitty}}
        \and
        \Infer{\rulename{BoolWF}}
        { }
        {\judgetp{\Gamma}{\boolty}}
        \and
        \Infer{\rulename{SNumWF}}
        {n > 0}
        {\judgetp{\Gamma}{\vartheta^{i}_{n}}}
        \and
        \Infer{\rulename{UNumWF}}
        {n > 0}
        {\judgetp{\Gamma}{\vartheta^{u}_{n}}}
        \and
        \Infer{\rulename{VecWF}}
        {\judgetp{\Gamma}{\tau} \\ \isnum{\tau} \\ c > 0}
        {\judgetp{\Gamma}{\vecty{\tau}{c}}}
        \and
        \Infer{\rulename{ArrowWF}}
        {\judgetps{\Gamma}{n}{A_i} \\ \judgetp{\Gamma}{B}}
        {\judgetp{\Gamma}{A_1, \dots, A_n \to B}}
        \and
        \Infer{\rulename{ForAllWF}}
        {\judgetp{\Gamma, \alpha}{A}}
        {\judgetp{\Gamma}{\faty{\alpha}{A}}}
        \and
        \Infer{\rulename{WFs}}
        {\judgetp{\Gamma}{A_1} \\\\ \vdots \\\\ \judgetp{\Gamma}{A_n}}
        {\hphantom{\sum}\judgetps{\Gamma}{n}{A}\hphantom{\sum}}
    \end{mathpar}
    \caption{Well-formedness of types}
\end{figure*}

\begin{figure*}[htbp]
    \judgbox{\unijudg{\Gamma}{A}{B}{C}{\Delta}}%
    {Under context $\Gamma$, types $A$ and $B$ unify to $C$ with output context $\Delta$.}
    \judgbox{\unijudgs{\Gamma}{A_i}{B_i}{n}{C_i}{\Delta}}%
    {Under context $\Gamma$, types $A_i$ and $B_i$ unify to $C_i$ with output context $\Delta$.}

    \begin{subfigure}{\linewidth}
        \begin{mathpar}
            \Infer{\rulename{EqUni}}
            {\judgetp{\Gamma}{A}}
            {\unijudg{\Gamma}{A}{A}{A}{\Gamma}}
            \and
            \Infer{\rulename{VecUni}}
            {\judgetp{\Gamma}{\vecty{\tau}{c}} \\ \judgetp{\Gamma}{\vecty{\sigma}{c}} \\ \unijudg{\Gamma}{\tau}{\sigma}{\pi}{\Delta}}
            {\unijudg{\Gamma}{\vecty{\tau}{c}}{\vecty{\sigma}{c}}{\vecty{\pi}{c}}{\Delta}}
            \\
            \Infer{\rulename{ArrowUni}}
            {\judgetp{\Gamma}{A_1, \dots, A_n \to R_A} \\ \judgetp{\Gamma}{B_1, \dots, B_N \to R_B} \\\\ \unijudgs{\Gamma}{A_i}{B_i}{n}{C_i}{\Delta} \\ \unijudg{\Gamma}{R_A}{R_B}{R_C}{\Delta}}
            {\unijudg{\Gamma}{A_1, \dots, A_n \to R_A}{B_1, \dots, B_n \to R_B}{C_1, \dots, C_n \to R_C}{\Delta}}
            \\
            % Two 'any' existentials
            \Infer{\rulename{ExAnyUni}}
            {\judgetp{\Gamma}{\exvar{\alpha}} \\ \judgetp{\Gamma}{\exvar{\beta}}}
            {\unijudg{\Gamma}{\exvar{\alpha}}{\exvar{\beta}}{\exvar{\alpha}}{\Delta}}
            \\
            % Two unspecified num existentials
            \Infer{\rulename{ExUNumUni}}
            {\judgetp{\Gamma}{\exvar{\numty}_1} \\ \judgetp{\Gamma}{\exvar{\numty}_2}}
            {\unijudg{\Gamma}{\exvar{\numty}_1}{\exvar{\numty}_2}{\exvar{\numty}_1}{\Delta}}
            \\
            \Infer{\rulename{ExSSNumUni}}
            {\judgetp{\Gamma}{\exvar{\numty}_{s_1,c_1}} \\ \judgetp{\Gamma}{\exvar{\numty}_{s_2, c_2}} \\\\ s_3 = s_1 \land s_2 \\ c_3 = \max(c_1, c_2)}
            {\unijudg{\Gamma}{\exvar{\numty}_{s_1,c_1}}{\exvar{\numty}_{s_2, c_2}}{\exvar{\numty}_{s_3, c_3}}{\Delta}}
            \\
        \end{mathpar}
    \end{subfigure}
\end{figure*}

\begin{figure*}[htbp]
    \ContinuedFloat
    \begin{subfigure}{\linewidth}
        \begin{mathpar}
            \Infer{\rulename{ExSUNumUni}}
            {\judgetp{\Gamma}{\exvar{\numty}_{s_1,c_1}} \\ \judgetp{\Gamma}{\exvar{\numty}}}
            {\unijudg{\Gamma}{\exvar{\numty}_{s_1,c_1}}{\exvar{\numty}}{\exvar{\numty}_{s_1, c_1}}{\Delta}}
            \\
            \Infer{\rulename{ExVecUni}}
            {\judgetp{\Gamma}{\exvar{\evecty}_1} \\ \judgetp{\Gamma}{\exvar{\evecty}_2}}
            {\unijudg{\Gamma}{\exvar{\evecty}_1}{\exvar{\evecty}_2}{\exvar{\evecty_1}}{\Delta}}
            \\
            \Infer{\rulename{ExVecCUni}}
            {\judgetp{\Gamma}{\exvar{\evecty}_\alpha} \\ \judgetp{\Gamma}{\vecty{\tau}{c}}}
            {\unijudg{\Gamma}{\exvar{\evecty}_\alpha}{\vecty{\tau}{c}}{\vecty{\tau}{c}}{\Delta}}
            \and
            \Infer{\rulename{ExUNumCUni}}
            {\judgetp{\Gamma}{\exvar{\numty}} \\ \judgetp{\Gamma}{\numty_{s, c}}}
            {\unijudg{\Gamma}{\exvar{\numty}}{\numty_{s, c}}{\numty_{s,c}}{\Delta}}
            \\
            \Infer{\rulename{ExSNumCUni}}
            {
                \judgetp{\Gamma}{\exvar{\numty}_{s_1, c_1}} \\ \judgetp{\Gamma}{\numty_{s_2, c_2}} \\\\
                \neg s_1 \lor s_2 \\ c_1 \le c_2
            }
            {\unijudg{\Gamma}{\exvar{\numty}_{s_1, c_1}}{\numty_{s_2, c_2}}{\numty_{s_2,c_2}}{\Delta}}
            \\
            \Infer{\rulename{ExAnyCUni}}
            {\judgetp{\Gamma}{\exvar{\alpha}} \\ \judgetp{\Gamma}{\alpha}}
            {\unijudg{\Gamma}{\exvar{\alpha}}{\alpha}{\alpha}{\Delta}}
            \and
            \Infer{\rulename{ForAllUni}}
            {\judgetp{\Gamma}{\faty{\alpha}{A}} \\ \judgetp{\Gamma}{B} \\ \unijudg{\Gamma, \exvar{\alpha}}{A[\alpha := \exvar{\alpha}]}{B}{B}{\Delta}}
            {\unijudg{\Gamma}{\faty{\alpha}{A}}{B}{B}{\Delta}}
            \\
            \Infer{\rulename{CommutUni}}
            {\unijudg{\Gamma}{A}{B}{C}{\Delta}}
            {\unijudg{\Gamma}{B}{A}{C}{\Delta}}
            \\
            \Infer{\rulename{Unis}}
            {
                \unijudg{\Gamma}{A_1}{B_1}{C_1}{\Theta_1} \\\\
                \unijudg{\Theta_1}{A_2}{B_2}{C_2}{\Theta_2} \\\\
                \vdots \\\\
                \unijudg{\Theta_{n - 1}}{A_n}{B_n}{C_n}{\Theta_n}
            }
            {\unijudgs{\Gamma}{A_i}{B_i}{n}{C_i}{\Theta_n}}
        \end{mathpar}
    \end{subfigure}
    \caption{Unification of types}
\end{figure*}

\begin{figure*}[htbp]
    \judgbox{\chkjudg{\Gamma}{e}{A}{\Delta}}%
    {Under input context $\Gamma$, $e$ checks against input type $A$,
    with output context $\Delta$} \\[1ex]
    \judgbox{\synjudg{\Gamma}{e}{A}{\Delta}}%
    {Under input context $\Gamma$, $e$ synthesizes output type $A$,
    with output context $\Delta$} \\[1ex]
    \judgbox{\synjudgs{\Gamma}{e_i}{n}{A_i}{\Delta}}%
    {Under input context $\Gamma$, $\family{e}{n}$ synthesizes types $\family{A}{n}$,
    with output context $\Delta$} \\[1ex]

    \begin{subfigure}{\linewidth}
        \begin{mathpar}
            \Infer{\rulename{UniToCheck}}
            {
                \synjudg{\Gamma}{e}{A}{\Theta} \\
                \unijudg{\Theta}{A}{B}{C}{\Delta}
            }
            {\chkjudg{\Gamma}{e}{B}{\Delta}}
            \\
            \Infer{\rulename{IdSyn}}
            {\synjudg{\Gamma}{\Gamma[x]}{A}{\Delta}}
            {\synjudg{\Gamma}{x}{A}{\Delta}}
            \\
            \Infer{\rulename{BoolSyn}}
            {x = \texttt{true} \lor x = \texttt{false}}
            {\synjudg{\Gamma}{x}{\boolty}{\Gamma}}
            \\
            \Infer{\rulename{SNumLitAnnSyn}}
            {\texttt{x = NuC} \\ C > 0 \\ 0 \le N < 2^C}
            {\synjudg{\Gamma}{x}{\numty_{\usn, C}}{\Gamma}}
            \\
            \Infer{\rulename{UNumLitAnnSyn}}
            {x = \texttt{NiC} \\ C > 0 \\ -2^{C - 1} \le N \le 2^{C - 1} - 1}
            {\synjudg{\Gamma}{x}{\numty_{\sn, C}}{\Gamma}}
            \\
            \Infer{\rulename{NLitSyn}}
            {
                x = N \\
                N \in \mathbb{Z} \\
                \textsf{sz} = \operatorname{\textsf{min-width}}(N) \\
                \textsf{sgn} = \operatorname{\textsf{sign}}(N)
            }
            {\synjudg{\Gamma}{x}{\exvar{\numty}_{\textsf{sgn}, \textsf{sz}}}{\Delta}}
            \and
            \Infer{\rulename{Vec1LitSyn}}
            {\synjudg{\Gamma}{e}{\tau}{\Delta} \\ \judgetp{\Delta}{\vecty{\tau}{1}}}
            {\synjudg{\Gamma}{[e]}{\vecty{\tau}{1}}{\Delta}}
            \and
            \Infer{\rulename{VecLitSyn}}
            {
                \synjudg{\Gamma}{[e_1, \dots, e_n]}{\vecty{\tau}{i}}{\Theta_1} \\\\
                \synjudg{\Theta_1}{e_{n + 1}}{\sigma}{\Theta_2} \\\\
                \unijudg{\Theta_2}{\sigma}{\tau}{\pi}{\Delta}
            }
            {\synjudg{\Gamma}{[e_1, \dots, e_{n + 1}]}{\vecty{\pi}{i + 1}}{\Delta}}
            \and
            \Infer{\rulename{NumFieldOpSyn}}
            {
                \textsf{op} \in [+, -, /, \cdot] \\\\
                \synjudg{\Gamma}{l}{\tau}{\Theta} \\
                \synjudg{\Gamma}{r}{\sigma}{\Theta} \\\\
                \isnum{\tau} \\
                \isnum{\sigma} \\\\
                \unijudg{\Theta}{\tau}{\sigma}{\pi}{\Delta}
            }
            {\synjudg{\Gamma}{l \textsf{ op } r}{\pi}{\Delta}}
        \end{mathpar}
    \end{subfigure}
\end{figure*}

\begin{figure*}[htbp]
    \ContinuedFloat
    \begin{subfigure}{\linewidth}
        \begin{mathpar}
            \Infer{\rulename{NumCmpOpSyn}}
            {
                \textsf{op} \in [<, \le, >, \ge] \\\\
                \synjudg{\Gamma}{l}{\tau}{\Theta} \\
                \synjudg{\Gamma}{r}{\sigma}{\Theta} \\\\
                \isnum{\tau} \\
                \isnum{\sigma} \\\\
                \chkjudg{\Theta}{\tau}{\sigma}{\Delta}
            }
            {\synjudg{\Gamma}{l \textsf{ op } r}{\boolty}{\Delta}}
            \and
            \Infer{\rulename{EqOpSyn}}
            {
                \textsf{op} \in [=, !=] \\\\
                \synjudg{\Gamma}{l}{\tau}{\Theta} \\
                \synjudg{\Gamma}{r}{\sigma}{\Theta} \\\\
                \chkjudg{\Theta}{\tau}{\sigma}{\Delta}
            }
            {\synjudg{\Gamma}{l \textsf{ op } r}{\boolty}{\Delta}}
            \and
            \Infer{\rulename{CallSyn}}
            {
                \synjudg{\Gamma}{f}{F}{\Theta_1} \\\\
                \synjudgs{\Theta_1}{e_i}{n}{A_i}{\Theta_2} \\\\
                \unijudg{\Theta_2}{F}{A_i, \dots, A_n \to R_A}{B_i, \dots, B_n \to R_B}{\Delta}
            }
            {\synjudg{\Gamma}{(f\; e_1\; \dots\; e_n)}{R_B}{\Delta}}
            \and
            \Infer{\rulename{IfSyn}}
            {
                \chkjudg{\Gamma}{\texttt{c}}{\boolty}{\Theta_1} \\\\
                \synjudg{\Theta_1}{\texttt{br\_t}}{A}{\Theta_2} \\
                \synjudg{\Theta_2}{\texttt{br\_f}}{B}{\Theta_3} \\\\
                \unijudg{\Theta_3}{A}{B}{C}{\Delta}
            }
            {\synjudg{\Gamma}{\texttt{(if c br\_t br\_f)}}{C}{\Delta}}
            \and
            \Infer{\rulename{Let0Syn}}
            {\synjudg{\Gamma}{b}{B}{\Delta}}
            {\synjudg{\Gamma}{\texttt{(let () b)}}{B}{\Delta}}
            \\
            \Infer{\rulename{LetSyn}}
            {
                \synjudg{\Gamma}{e_1}{A}{\Theta} \\\\
                \synjudg{\Theta, (x: A)}{\texttt{(let (\dots) b)}}{B}{\Delta}
            }
            {\synjudg{\Gamma}{\texttt{(let ((x, e\_1) \dots) b)}}{B}{\Delta}}
            \and
            \Infer{\rulename{LetAnnSyn}}
            {
                \chkjudg{\Gamma}{e_1}{T}{\Theta} \\\\
                \synjudg{\Theta, (x: T)}{\texttt{(let (\dots) b)}}{B}{\Delta}
            }
            % LaTeX vs my sane spacing
            {\synjudg{\Gamma}{\texttt{(let ((x:\!\!\!\!\! T, e\_1) \dots) b)}}{B}{\Delta}}
            \and
            \Infer{\rulename{ScanSyn}}
            {}
            {\synjudg{\Gamma}{\texttt{scan}}{\faty{\evecty_{\alpha}}{\evecty_{\alpha} \to \evecty_{\alpha}}}{\Delta}}
        \end{mathpar}
    \end{subfigure}
    \caption{Inference and checking of types}
\end{figure*}

% I, in fact, do not want my figures in the middle of my bibliography
\clearpage
\section{Zinnia Examples}
\begin{lstlisting}
    let main: u8 = (let ((x : Vec<i8, 8>, [1, 4, 5, 7, 1, 2, 3, 4])) 2);
\end{lstlisting}
Example of using vector types - "main" is defined as returning an 8 bit integer, x is defined as getting a vector of eight 8-bit integers, and the two is returned as the result.
\begin{lstlisting}
    let main: i8 = (let ((x: i8, (+ 1u8 4i8))) (+ x 3));
\end{lstlisting}
Example of a mismatch caught by the type checker - 1 (an unsigned int) and 4 (a signed int) cannot be added together to get a signed int as a result.
\clearpage
\nocite{*}
\printbibliography

\end{document}
