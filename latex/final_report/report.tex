\documentclass[12pt]{article}

\usepackage[T1]{fontenc}
\usepackage{graphicx} % Required for inserting images
\usepackage[margin=1in]{geometry}
\usepackage{xcolor}
\usepackage{listings}
\usepackage{mathpartir}
\usepackage{minted}
\usepackage{xparse}
\usepackage{graphicx}
\usepackage[normalem]{ulem}
\usepackage{soul}
\usepackage{float}
\usepackage{hyperref}
\usepackage{amsmath}
\usepackage{xspace}
\usepackage{euler}
\usepackage{amsfonts}
\usepackage{mathtools}
\usepackage{subcaption}

\NewDocumentCommand{\codeword}{v}{%
\texttt{\textcolor{blue}{#1}}%
}
\usepackage{hyperref}

\input type_macros

\title{CMSC838L - Final report}
\author{Arjun Vedantham \\ Yusuf Bham}
\date{May 2024}

\begin{document}

\maketitle

\section{Introduction and Motivation}
Digital signal processing techniques are extremely important in telecommunications, computer vision, and a number of other related fields.
In particular, digital signal processing techniques form a key component behind the idea of software defined radio (SDR),
which refers to analyzing digital samples that represent radio signals with software, instead of discrete hardware components that operate
over signals in analog formats. Software defined radio presents a notable improvement in flexibility for radio engineers, and removes the
need for specialized hardware components - instead, new signal demodulation techniques or formats can be deployed just through a simple software
update.

SDR users typically define signal processing pipelines using platforms like GNURadio. GNURadio presents a graphical format for creating these
pipelines, with discrete blocks representing a signal source, signal sink, or an intermediate step in the processing pipeline. As an example,
see the "flowgraph" (as called in GNURadio's documentation) below. This starts by instantiating a signal source from an RTL-SDR (a type of hobbyist SDR that can be used
over USB with consumer PCs), and sets both a sampling rate (32000 Hz) and a listening frequency (signals at 433 MHz). From here, these samples
are fed into a low pass filter block (which smooths out high frequency noise in the signal), and the resulting signal is transformed into
a stream that is passed to a GUI block that graphs the signal, using a Fast Fourier Transform (FFT) to move the signal into the frequency domain.

This simple flowgraph is stored in an XML format, and is used by GNURadio's backend to generate a Python script that actually runs the defined
processing pipeline. In addition, there are also C/C++ modules loaded into the runtime system for low level tasks - for instance, a USB driver for the SDR.

\includegraphics[width=\linewidth]{images/gnuradio.png}

\subsection{Problems Identified with State of the Art}
There are number of problems with this current approach. First, GNURadio's practice of emitting Python scripts means that parallelism is
limited on two fronts - first, because of language design choices (Python's infamous "global interpreter lock", which essentially forbids
runtime concurrency), and also because we are ultimately running this script on standard PC hardware, which uses an inherently sequential
von Neumann architecture. Additionally, as previously mentioned, there is also an extensive library of C/C++ modules, and the implementation
of these modules are opaque to the Python-level code generated by GNURadio's flowgraph compiler.

As such, we identified two research questions that we aimed to answer in this project:

\begin{itemize}
    \item Could we use hardware acceleration to get better performance and greater parallelism for DSP applications?
    \item Could we design a language that is more conducive to defining correct DSP pipelines?
\end{itemize}

\section{Literature Review}
We started by conducting a literature review of existing languages designed for DSP problems.
\subsection{Ziria}
One of the first papers we considered as Ziria, a domain specific language that was
designed to aid development in implementations of the physical layer of wireless protocols.
Ziria presented a functional language design syntax, and was specifically intended for wireless protocol
implementations on IOT hardware. As such, it contained many primitives that we thought would
be important to add to our language - for instance, an "FFT" primitive function. However Ziria had a key limitation -
it was designed for standard CPUs, which meant that there were still parallelism limitations.

\subsection{Calyx}
One technique generally used for hardware acceleration for specialized applications like this
is to deploy them to FPGAs. One example of this was the Catapult paper that we read in class,
where Microsoft deployed FPGAs to accelerate running PageRank as part of their Bing server infrastructure.
However, FPGAs are notoriously difficult to program, and generally require extremely fine-grained circuit
configurations written in a hardware description language like Verilog.

Calyx is an intermediate representation for compilers developed by the CAPRA research group at Cornell.
It defines circuits in three distinct parts - a collection of memories (consisting of combinational memories/
flip-flops and registers), wire groups (which denote assignments between different memory components
in the circuit), and a statically defined control schedule that orders wire assignments.
Calyx has already been used in the Filament HDL, another domain specific language project from the CAPRA
group that incorporated signal timing into the language's type system.

\section{Technical Contribution}
We decided to use the Calyx IR and design a more general, hardware acceleratable language for DSP tasks, called Zinnia.
\footnote{Named "Zinnia" because "calyx" refers to the petals of a flower and zinnias are a type of flower. Plus it sounds like Ziria.}
We also considered emitting circuits using CIRCT, the LLVM framework that allows compilers to generate
MLIR that is subsequently lowered to a Verilog hardware description, however we quickly found that
CIRCT lacked the project maturity needed to develop even a basic language around it. This included
no binaries to link against, thus requiring us to compile a large subset of the LLVM project, which was not practical.
<<<<<<< HEAD
Calyx also had better documentation for its IR, and a small standard library of memory cells that could be easily integrated
into circuits synthesized when the compiler lowers from the IR to a Verilog hardware description.
\subsection{Code Generation}
The compiler that we wrote for Zinnia traverses the AST recursively. Since there is no concept of dynamic
memory allocation for circuits, we focused on generating the required memories for the circuit first.

Additionally, while Calyx has a "par" primitive for parallelizing parts of the circuit, Zinnia currently only generates
circuits using the "seq" ("sequential") control flow keyword for easier debugging and testing. Even though parallelism
at the user level is limited, we still hoped to expose some of the potential parallel speedups through the use
of a function primitive that could be used to get implicit parallelism.

\subsection{Prefix Sums Scan}
To expose some parallelism without explicitly supporting copmiling using the "par" control flow block,
we implemented a version of parallel scan using the prefix sums algorithm.

\section{Evaluation}
We decided to evaluate our language in three different ways: correctness testing, scalability testing, and hardware testing.
\subsection{Correctness Testing}
To verify the correctness of the language, we used the Cocotb RTL testing framework. This allows
us to run a simulated version of the circuit's clock and write unit tests around elements of the circuits
that we generate.
\subsection{Scalability Testing}
Second, we focused on testing scalability. For this, we focused on evaluating the "scan" primitive, since
it is the main way end-users would be able to obtain parallelism through the language (at least, as it is currently implemented).
We found that in simulation, our parallel scan implementation always took 71 cycles to generate outputs, given a set of 8 integers
to iterate over. While parallel scan theoretically provides work bounds of $O(n)$ and span bounds of $O(lg(n))$, in practice the
work and span bounds of our implementation are worse. This is because we were not sure if it was possible to instantiate
an arbitrarily high number of registers, so we focused on using the combinational memory primitives to hold intermediate values
(particularly between the "sweep-up" and "sweep-down" phases of parallel scan). Combinational memory primitives in the Calyx IR
are exclusive read/write memory cells, and take at least one cycle to set the data address and read the stored value out of the memory
into a register. This restriction essentially limited the parallelism that we could achieve to only a few steps of the algorithm - specifically,
summing values between nodes at each level of the prefix sums tree, since the additions were purely combinational and depended only
on values in registers that were ready to go at the last cycle.
\subsection{Physical Testing}
We hoped to eventually deploy circuits that were synthesized using Zinnia to a Lattice Icestick FPGA.
This FPGA can be used with consumer devices over a USB connection, and has a large library of open source tooling.
This includes the Yosys synthesis toolkit (which handles transforming high level Verilog hardware descriptions into
lower level RTL circuits), the nextpnr place and route tool (which handles connections between logic units
on the FPGA), and iceprog, an open source programming tool that could deploy circuits with complete routing
to the flash memory on-board the Icestick.

Circuits synthesized by Calyx include three signals by default - a "go" line, which when activated,
activates the circuit, a "clk" (clock) line, which handles cycle-level signalling for the sequential logic
elements of the circuit, and a "reset" line, which can be used to reset the circuit while active.

In order to actually use the synthesized circuits, the "go" line must be pulled to logical high, and
while the reset lines needed to be set to logical low, and the clock line must be tied to the 12 MHz
oscillator built into the Icestick. Values for the "scan" primitive could then be loaded in from the Icestick's
block RAM module.

To support dynamically loading values into block RAM, we wrote a small serial communication driver for the Icestick.
Specifically, this was a form of one way (half-duplex) SPI, with an Arduino serving as the primary device on the SPI
bus, and the Icestick serving as the secondary device. We chose SPI because it is relatively easy to implement
on the receiving side (in fact, a shift register is enough to receive data transmitted over the data line).
While testing the SPI driver, we wanted to use an external clock source to control the speed of data transmission,
and ensure that the Icestick was sampling the data line in phase with the transmitting device's clock (in this case
an Arduino). Unfortunately, setting the clock line for the circuit loaded onto the FPGA also sets the clock line
for the USB programmer chip, which requires a 12MHz signal in order to function correctly. This misconfiguration
prevented us from loading new circuits onto the FPGA, and required us to use simulation as our primary evaluation
method instead.

\section{Conclusion}
In the end, we were able to implement a version of the scan primitive in the Calyx IR, implement a bidirectional
typing system, add some basic language features into our language, and use external circuit verification and simulation
tools to show that our circuits performed as the high level program specified.

However, there is still room for improvement - we do not have support for looping structures, even though the Calyx IR supports
it. We were also not able to show our circuits running on real hardware, which was the ultimate goal of the project.

One obstacle that we did not foresee was the difficulty of working with the Calyx IR from Rust. While LLVM's CIRCT project
has a robust Rust API, it seems that the authors of the Calyx IR primarily want language authors to use their IR from
a Python builder module or the CIRCT toolchain, even though the Filament HDL (which was authored by the same research
group and uses Calyx as its IR) is also written in Rust. For some issues, like linking against the combinational memory
primitives or inlining other components, the Rust library documentation was so poor that we ended up looking through
Filament's implementation and using that as a guide for building our compiler.

\section{Typing}
bro typechecks

\begin{figure*}[htbp]
    \[
        \begin{array}{llcll}
            \text{Types} & A, B, C & \bnfas & 
            \unitty &\bnfalt \alpha \bnfalt \exvar{\alpha} \\ & & & &\bnfalt \faty{\alpha}{A} \\ & & & &\bnfalt A_1, \dots, A_n \to B
            \\[8pt]
            \text{Monotypes} & \tau,\sigma,\pi & \bnfas &
            \unitty &\bnfalt \alpha \bnfalt \exvar{\alpha} \\
                    & & & &\bnfalt \tau_1, \dots, \tau_n \to \sigma \\
                    & & & &\bnfalt \vartheta \bnfalt \vartheta_{i, s} \bnfalt \exvar{\vartheta} \bnfalt \exvar{\vartheta}_{i, s} \\
                    & & & &\bnfalt \vecty{\tau}{c} \bnfalt \exvar{\evecty} \\
                    & & & &\bnfalt \boolty 
            \\[8pt]
            \text{Contexts} & \Gamma, \Delta, \Theta & \bnfas &
            \cdot
                            &\bnfalt \Gamma, \alpha 
            \bnfalt \Gamma, (x:A)
        \end{array}
    \]
    \caption{Syntax of types, monotypes, and contexts.}
\end{figure*}

\begin{figure*}[htbp]
    \judgbox{\judgetp{\Gamma}{A}}%
    {Under context $\Gamma$, type $A$ is well-formed.}\\
    \judgbox{\judgetps{\Gamma}{n}{A}}%
    {Under context $\Gamma$, types $\family{A}{n}$ are well-formed.}

    \begin{mathpar}
        \Infer{\rulename{UnitWF}}
        { }
        {\judgetp{\Gamma}{\unitty}}
        \and
        \Infer{\rulename{BoolWF}}
        { }
        {\judgetp{\Gamma}{\boolty}}
        \and
        \Infer{\rulename{SNumWF}}
        {n > 0}
        {\judgetp{\Gamma}{\vartheta^{i}_{n}}}
        \and
        \Infer{\rulename{UNumWF}}
        {n > 0}
        {\judgetp{\Gamma}{\vartheta^{u}_{n}}}
        \and
        \Infer{\rulename{VecWF}}
        {\judgetp{\Gamma}{\tau} \\ \isnum{\tau} \\ c > 0}
        {\judgetp{\Gamma}{\vecty{\tau}{c}}}
        \and
        \Infer{\rulename{ArrowWF}}
        {\judgetps{\Gamma}{n}{A_i} \\ \judgetp{\Gamma}{B}}
        {\judgetp{\Gamma}{A_1, \dots, A_n \to B}}
        \and
        \Infer{\rulename{ForAllWF}}
        {\judgetp{\Gamma, \alpha}{A}}
        {\judgetp{\Gamma}{\faty{\alpha}{A}}}
        \and
        \Infer{\rulename{WFs}}
        {\judgetp{\Gamma}{A_1} \\\\ \vdots \\\\ \judgetp{\Gamma}{A_n}}
        {\hphantom{\sum}\judgetps{\Gamma}{n}{A}\hphantom{\sum}}
    \end{mathpar}
    \caption{Well-formedness of types}
\end{figure*}

\begin{figure*}[htbp]
    \judgbox{\unijudg{\Gamma}{A}{B}{C}{\Delta}}%
    {Under context $\Gamma$, types $A$ and $B$ unify to $C$ with output context $\Delta$.}
    \judgbox{\unijudgs{\Gamma}{A_i}{B_i}{n}{C_i}{\Delta}}%
    {Under context $\Gamma$, types $A_i$ and $B_i$ unify to $C_i$ with output context $\Delta$.}

    \begin{subfigure}{\linewidth}
        \begin{mathpar}
            \Infer{\rulename{EqUni}}
            {\judgetp{\Gamma}{A}}
            {\unijudg{\Gamma}{A}{A}{A}{\Gamma}}
            \and
            \Infer{\rulename{VecUni}}
            {\judgetp{\Gamma}{\vecty{\tau}{c}} \\ \judgetp{\Gamma}{\vecty{\sigma}{c}} \\ \unijudg{\Gamma}{\tau}{\sigma}{\pi}{\Delta}}
            {\unijudg{\Gamma}{\vecty{\tau}{c}}{\vecty{\sigma}{c}}{\vecty{\pi}{c}}{\Delta}}
            \\
            \Infer{\rulename{ArrowUni}}
            {\judgetp{\Gamma}{A_1, \dots, A_n \to R_A} \\ \judgetp{\Gamma}{B_1, \dots, B_N \to R_B} \\\\ \unijudgs{\Gamma}{A_i}{B_i}{n}{C_i}{\Delta} \\ \unijudg{\Gamma}{R_A}{R_B}{R_C}{\Delta}}
            {\unijudg{\Gamma}{A_1, \dots, A_n \to R_A}{B_1, \dots, B_n \to R_B}{C_1, \dots, C_n \to R_C}{\Delta}}
            \\
            % Two 'any' existentials
            \Infer{\rulename{ExAnyUni}}
            {\judgetp{\Gamma}{\exvar{\alpha}} \\ \judgetp{\Gamma}{\exvar{\beta}}}
            {\unijudg{\Gamma}{\exvar{\alpha}}{\exvar{\beta}}{\exvar{\alpha}}{\Delta}}
            \\
            % Two unspecified num existentials
            \Infer{\rulename{ExUNumUni}}
            {\judgetp{\Gamma}{\exvar{\numty}_1} \\ \judgetp{\Gamma}{\exvar{\numty}_2}}
            {\unijudg{\Gamma}{\exvar{\numty}_1}{\exvar{\numty}_2}{\exvar{\numty}_1}{\Delta}}
            \\
            \Infer{\rulename{ExSSNumUni}}
            {\judgetp{\Gamma}{\exvar{\numty}_{s_1,c_1}} \\ \judgetp{\Gamma}{\exvar{\numty}_{s_2, c_2}} \\\\ s_3 = s_1 \land s_2 \\ c_3 = \max(c_1, c_2)}
            {\unijudg{\Gamma}{\exvar{\numty}_{s_1,c_1}}{\exvar{\numty}_{s_2, c_2}}{\exvar{\numty}_{s_3, c_3}}{\Delta}}
            \\
        \end{mathpar}
    \end{subfigure}
\end{figure*}

\begin{figure*}[htbp]
    \ContinuedFloat
    \begin{subfigure}{\linewidth}
        \begin{mathpar}
            \Infer{\rulename{ExSUNumUni}}
            {\judgetp{\Gamma}{\exvar{\numty}_{s_1,c_1}} \\ \judgetp{\Gamma}{\exvar{\numty}}}
            {\unijudg{\Gamma}{\exvar{\numty}_{s_1,c_1}}{\exvar{\numty}}{\exvar{\numty}_{s_1, c_1}}{\Delta}}
            \\
            \Infer{\rulename{ExVecUni}}
            {\judgetp{\Gamma}{\exvar{\evecty}_1} \\ \judgetp{\Gamma}{\exvar{\evecty}_2}}
            {\unijudg{\Gamma}{\exvar{\evecty}_1}{\exvar{\evecty}_2}{\exvar{\evecty_1}}{\Delta}}
            \\
            \Infer{\rulename{ExVecCUni}}
            {\judgetp{\Gamma}{\exvar{\evecty}_\alpha} \\ \judgetp{\Gamma}{\vecty{\tau}{c}}}
            {\unijudg{\Gamma}{\exvar{\evecty}_\alpha}{\vecty{\tau}{c}}{\vecty{\tau}{c}}{\Delta}}
            \and
            \Infer{\rulename{ExUNumCUni}}
            {\judgetp{\Gamma}{\exvar{\numty}} \\ \judgetp{\Gamma}{\numty_{s, c}}}
            {\unijudg{\Gamma}{\exvar{\numty}}{\numty_{s, c}}{\numty_{s,c}}{\Delta}}
            \\
            \Infer{\rulename{ExSNumCUni}}
            {
                \judgetp{\Gamma}{\exvar{\numty}_{s_1, c_1}} \\ \judgetp{\Gamma}{\numty_{s_2, c_2}} \\\\
                \neg s_1 \lor s_2 \\ c_1 \le c_2
            }
            {\unijudg{\Gamma}{\exvar{\numty}_{s_1, c_1}}{\numty_{s_2, c_2}}{\numty_{s_2,c_2}}{\Delta}}
            \\
            \Infer{\rulename{ExAnyCUni}}
            {\judgetp{\Gamma}{\exvar{\alpha}} \\ \judgetp{\Gamma}{\alpha}}
            {\unijudg{\Gamma}{\exvar{\alpha}}{\alpha}{\alpha}{\Delta}}
            \and
            \Infer{\rulename{ForAllUni}}
            {\judgetp{\Gamma}{\faty{\alpha}{A}} \\ \judgetp{\Gamma}{B} \\ \unijudg{\Gamma, \exvar{\alpha}}{A[\alpha := \exvar{\alpha}]}{B}{B}{\Delta}}
            {\unijudg{\Gamma}{\faty{\alpha}{A}}{B}{B}{\Delta}}
            \\
            \Infer{\rulename{CommutUni}}
            {\unijudg{\Gamma}{A}{B}{C}{\Delta}}
            {\unijudg{\Gamma}{B}{A}{C}{\Delta}}
            \\
            \Infer{\rulename{Unis}}
            {
                \unijudg{\Gamma}{A_1}{B_1}{C_1}{\Theta_1} \\\\ 
                \unijudg{\Theta_1}{A_2}{B_2}{C_2}{\Theta_2} \\\\ 
                \vdots \\\\ 
                \unijudg{\Theta_{n - 1}}{A_n}{B_n}{C_n}{\Theta_n}
            }
            {\unijudgs{\Gamma}{A_i}{B_i}{n}{C_i}{\Theta_n}}
        \end{mathpar}
    \end{subfigure}
    \caption{Unification of types}
\end{figure*}

\begin{figure*}[htbp]
    \judgbox{\chkjudg{\Gamma}{e}{A}{\Delta}}%
    {Under input context $\Gamma$, $e$ checks against input type $A$,
    with output context $\Delta$} \\[1ex]
    \judgbox{\synjudg{\Gamma}{e}{A}{\Delta}}%
    {Under input context $\Gamma$, $e$ synthesizes output type $A$,
    with output context $\Delta$} \\[1ex]
    \judgbox{\synjudgs{\Gamma}{e_i}{n}{A_i}{\Delta}}%
    {Under input context $\Gamma$, $\family{e}{n}$ synthesizes types $\family{A}{n}$,
    with output context $\Delta$} \\[1ex]

    \begin{subfigure}{\linewidth}
        \begin{mathpar}
            \Infer{\rulename{UniToCheck}}
            {
                \synjudg{\Gamma}{e}{A}{\Theta} \\
                \unijudg{\Theta}{A}{B}{C}{\Delta}
            }
            {\chkjudg{\Gamma}{e}{B}{\Delta}}
            \\
            \Infer{\rulename{IdSyn}}
            {\synjudg{\Gamma}{\Gamma[x]}{A}{\Delta}}
            {\synjudg{\Gamma}{x}{A}{\Delta}}
            \\
            \Infer{\rulename{BoolSyn}}
            {x = \texttt{true} \lor x = \texttt{false}}
            {\synjudg{\Gamma}{x}{\boolty}{\Gamma}}
            \\
            \Infer{\rulename{SNumLitAnnSyn}}
            {\texttt{x = NuC} \\ C > 0 \\ 0 \le N < 2^C}
            {\synjudg{\Gamma}{x}{\numty_{\usn, C}}{\Gamma}}
            \\
            \Infer{\rulename{UNumLitAnnSyn}}
            {x = \texttt{NiC} \\ C > 0 \\ -2^{C - 1} \le N \le 2^{C - 1} - 1}
            {\synjudg{\Gamma}{x}{\numty_{\sn, C}}{\Gamma}}
            \\
            \Infer{\rulename{NLitSyn}}
            {
                x = N \\
                N \in \mathbb{Z} \\ 
                \textsf{sz} = \operatorname{\textsf{min-width}}(N) \\
                \textsf{sgn} = \operatorname{\textsf{sign}}(N)
            }
            {\synjudg{\Gamma}{x}{\exvar{\numty}_{\textsf{sgn}, \textsf{sz}}}{\Delta}}
            \and
            \Infer{\rulename{Vec1LitSyn}}
            {\synjudg{\Gamma}{e}{\tau}{\Delta} \\ \judgetp{\Delta}{\vecty{\tau}{1}}}
            {\synjudg{\Gamma}{[e]}{\vecty{\tau}{1}}{\Delta}}
            \and
            \Infer{\rulename{VecLitSyn}}
            {
                \synjudg{\Gamma}{[e_1, \dots, e_n]}{\vecty{\tau}{i}}{\Theta_1} \\\\
                \synjudg{\Theta_1}{e_{n + 1}}{\sigma}{\Theta_2} \\\\
                \unijudg{\Theta_2}{\sigma}{\tau}{\pi}{\Delta}
            }
            {\synjudg{\Gamma}{[e_1, \dots, e_{n + 1}]}{\vecty{\pi}{i + 1}}{\Delta}}
            \and
            \Infer{\rulename{NumFieldOpSyn}}
            {
                \textsf{op} \in [+, -, /, \cdot] \\\\
                \synjudg{\Gamma}{l}{\tau}{\Theta} \\
                \synjudg{\Gamma}{r}{\sigma}{\Theta} \\\\
                \isnum{\tau} \\
                \isnum{\sigma} \\\\
                \unijudg{\Theta}{\tau}{\sigma}{\pi}{\Delta}
            }
            {\synjudg{\Gamma}{l \textsf{ op } r}{\pi}{\Delta}}
        \end{mathpar}
    \end{subfigure}
\end{figure*}

\begin{figure*}[htbp]
    \ContinuedFloat
    \begin{subfigure}{\linewidth}
        \begin{mathpar}
            \Infer{\rulename{NumCmpOpSyn}}
            {
                \textsf{op} \in [<, \le, >, \ge] \\\\
                \synjudg{\Gamma}{l}{\tau}{\Theta} \\
                \synjudg{\Gamma}{r}{\sigma}{\Theta} \\\\
                \isnum{\tau} \\
                \isnum{\sigma} \\\\
                \chkjudg{\Theta}{\tau}{\sigma}{\Delta}
            }
            {\synjudg{\Gamma}{l \textsf{ op } r}{\boolty}{\Delta}}
            \and
            \Infer{\rulename{EqOpSyn}}
            {
                \textsf{op} \in [=, !=] \\\\
                \synjudg{\Gamma}{l}{\tau}{\Theta} \\
                \synjudg{\Gamma}{r}{\sigma}{\Theta} \\\\
                \chkjudg{\Theta}{\tau}{\sigma}{\Delta}
            }
            {\synjudg{\Gamma}{l \textsf{ op } r}{\boolty}{\Delta}}
            \and
            \Infer{\rulename{CallSyn}}
            {
                \synjudg{\Gamma}{f}{F}{\Theta_1} \\\\
                \synjudgs{\Theta_1}{e_i}{n}{A_i}{\Theta_2} \\\\
                \unijudg{\Theta_2}{F}{A_i, \dots, A_n \to R_A}{B_i, \dots, B_n \to R_B}{\Delta}
            }
            {\synjudg{\Gamma}{(f\; e_1\; \dots\; e_n)}{R_B}{\Delta}}
            \and
            \Infer{\rulename{IfSyn}}
            {
                \chkjudg{\Gamma}{\texttt{c}}{\boolty}{\Theta_1} \\\\
                \synjudg{\Theta_1}{\texttt{br\_t}}{A}{\Theta_2} \\
                \synjudg{\Theta_2}{\texttt{br\_f}}{B}{\Theta_3} \\\\
                \unijudg{\Theta_3}{A}{B}{C}{\Delta}
            }
            {\synjudg{\Gamma}{\texttt{(if c br\_t br\_f)}}{C}{\Delta}}
            \and
            \Infer{\rulename{Let0Syn}}
            {\synjudg{\Gamma}{b}{B}{\Delta}}
            {\synjudg{\Gamma}{\texttt{(let () b)}}{B}{\Delta}}
            \\
            \Infer{\rulename{LetSyn}}
            {
                \synjudg{\Gamma}{e_1}{A}{\Theta} \\\\
                \synjudg{\Theta, (x: A)}{\texttt{(let (\dots) b)}}{B}{\Delta}
            }
            {\synjudg{\Gamma}{\texttt{(let ((x, e\_1) \dots) b)}}{B}{\Delta}}
            \and
            \Infer{\rulename{LetAnnSyn}}
            {
                \chkjudg{\Gamma}{e_1}{T}{\Theta} \\\\
                \synjudg{\Theta, (x: T)}{\texttt{(let (\dots) b)}}{B}{\Delta}
            }
            % LaTeX vs my sane spacing
            {\synjudg{\Gamma}{\texttt{(let ((x:\!\!\!\!\! T, e\_1) \dots) b)}}{B}{\Delta}}
            \and
            \Infer{\rulename{ScanSyn}}
            {}
            {\synjudg{\Gamma}{\texttt{scan}}{\faty{\evecty_{\alpha}}{\evecty_{\alpha} \to \evecty_{\alpha}}}{\Delta}}
            \and
            \Infer{\rulename{FilterSyn}}
            {}
            {\synjudg{\Gamma}{\texttt{filter}}{\faty{\evecty_{\alpha}}{\evecty_{\alpha} \to \evecty_{\alpha}}}{\Delta}}
        \end{mathpar}
    \end{subfigure}
    \caption{Inference and checking of types}
\end{figure*}

\end{document}
